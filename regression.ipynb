{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b875c303-b986-45ef-8692-91a0ba8ca171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "#initial data reading \n",
    "df = pd.read_csv(\"train.csv\")\n",
    "column_means = df.mean(numeric_only=True)\n",
    "df = df.fillna(column_means)\n",
    "print(df.head())\n",
    "\n",
    "#data extraction \n",
    "X_train = df.drop(columns=[\"close\",\"date\",\"symbols\"]).values#skiping non numeric data and target\n",
    "y_train = df[\"close\"].values\n",
    "\n",
    "\n",
    "\n",
    "print(X_train.shape)#prints structure\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_train[:5]) #prints values  \n",
    "print(y_train[:5])  \n",
    "\n",
    "\n",
    "#plot the data\n",
    "\n",
    "#normalize the data \n",
    "import numpy as np\n",
    "mu = np.mean(X_train, axis=0)\n",
    "sigma = np.std(X_train, axis=0)\n",
    "X_train_norm = (X_train - mu) / sigma\n",
    "\n",
    "#plot again\n",
    "\n",
    "#function generation \n",
    "m, n = X_train_norm.shape\n",
    "np.random.seed(1)\n",
    "w = np.random.rand(n)\n",
    "b = 0.0\n",
    "\n",
    "#cost function generation \n",
    "def compute_cost(X, y, w, b):\n",
    "    \"\"\"\n",
    "    Computes the cost (Mean Squared Error) for linear regression.\n",
    "    \"\"\"\n",
    "    m = X.shape[0]\n",
    "    # Prediction: f_wb = X * w + b (using NumPy dot product)\n",
    "    f_wb = X @ w + b\n",
    "    \n",
    "    # Calculate squared error\n",
    "    cost = (f_wb - y)**2\n",
    "    \n",
    "    # Return the mean cost (scaled by 1/2m for cleaner gradient)\n",
    "    total_cost = np.sum(cost) / (2 * m)\n",
    "    return total_cost\n",
    "\n",
    "#gradient descent function generation\n",
    "# --- 1. GRADIENT FUNCTION (The missing step to calculate the direction) ---\n",
    "def compute_gradient(X, y, w, b):\n",
    "    \"\"\"\n",
    "    Computes the gradient (partial derivatives) for w and b.\n",
    "    \"\"\"\n",
    "    m = X.shape[0]\n",
    "    f_wb = X @ w + b    # Predictions: X * w + b\n",
    "    err = f_wb - y      # Prediction error: (predicted - actual)\n",
    "\n",
    "    # Vectorized gradient for all weights (dw)\n",
    "    # dw = X_T * err / m\n",
    "    dw = (X.T @ err) / m\n",
    "\n",
    "    # Gradient for bias (db)\n",
    "    # db = Sum(err) / m\n",
    "    db = np.sum(err) / m\n",
    "\n",
    "    return dw, db\n",
    "\n",
    "# --- 2. GRADIENT DESCENT LOOP (The missing step to iteratively update w and b) ---\n",
    "def gradient_descent(X, y, w_in, b_in, alpha, num_iters, cost_function, gradient_function):\n",
    "    \"\"\"\n",
    "    Performs gradient descent to learn w and b.\n",
    "    \"\"\"\n",
    "    w = w_in\n",
    "    b = b_in\n",
    "    J_history = []  # To store cost history for later analysis\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        # Calculate the gradient \n",
    "        dw, db = gradient_function(X, y, w, b)\n",
    "\n",
    "        # Update rule: Simultaneously update w and b\n",
    "        w = w - alpha * dw\n",
    "        b = b - alpha * db\n",
    "\n",
    "        # Record and print the cost\n",
    "        cost = cost_function(X, y, w, b)\n",
    "        J_history.append(cost)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iteration {i:4d}: Cost {cost:.2f}\")\n",
    "\n",
    "    return w, b, J_history\n",
    "\n",
    "# --- APPLY GRADIENT DESCENT ---\n",
    "iterations = 3000\n",
    "\n",
    "alpha = 0.01  # Learning rate\n",
    "\n",
    "# Run the algorithm using your normalized data and defined parameters\n",
    "w_final, b_final, J_hist = gradient_descent(\n",
    "    X_train_norm, y_train, w, b, alpha, iterations, compute_cost, compute_gradient\n",
    ")\n",
    "\n",
    "print(\"\\n--- Manual Gradient Descent Training Complete ---\")\n",
    "print(f\"Optimal weights (w): {w_final}\")\n",
    "print(f\"Optimal bias (b): {b_final:.2f}\")\n",
    "\n",
    "# --- DEMONSTRATE PREDICTION ---\n",
    "def predict_manual(X, w, b):\n",
    "    return X @ w + b\n",
    "\n",
    "y_pred_manual = predict_manual(X_train_norm[:5], w_final, b_final)\n",
    "\n",
    "print(\"\\n--- Model Performance on First 5 Samples ---\")\n",
    "print(f\"Actual Prices (y_train[:5]): \\t{y_train[:5]}\")\n",
    "print(f\"Predicted Prices: \\t\\t{y_pred_manual}\")\n",
    "# Set hyperparameters\n",
    "\n",
    "# Plot cost history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(iterations), J_hist)\n",
    "plt.title(\"Cost (MSE) vs. Iterations\")\n",
    "plt.xlabel(\"Iteration Number\")\n",
    "plt.ylabel(\"Cost (Mean Squared Error)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCost history plot displayed.\")\n",
    "\n",
    "# --- (Add this after your cost plot code) ---\n",
    "\n",
    "print(\"Generating Actual vs. Predicted plot...\")\n",
    "\n",
    "# 1. Get predictions for ALL data\n",
    "y_pred_full = predict_manual(X_train_norm, w_final, b_final)\n",
    "\n",
    "# 2. Create the scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_train, y_pred_full, alpha=0.5, label='Actual vs. Predicted')\n",
    "\n",
    "# 3. Add a perfect-prediction line (y=x)\n",
    "min_val = min(np.min(y_train), np.min(y_pred_full))\n",
    "max_val = max(np.max(y_train), np.max(y_pred_full))\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Perfect Prediction')\n",
    "\n",
    "plt.title('Model Performance: Actual vs. Predicted')\n",
    "plt.xlabel('Actual Close Price')\n",
    "plt.ylabel('Predicted Close Price')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
